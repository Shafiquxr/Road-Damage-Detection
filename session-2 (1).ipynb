{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14294607,"sourceType":"datasetVersion","datasetId":9124799},{"sourceId":14473522,"sourceType":"datasetVersion","datasetId":9244496}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, sys, subprocess, importlib\nfrom pathlib import Path\n\n# Disable trackers\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"WANDB_MODE\"] = \"disabled\"\nos.environ[\"WANDB_SILENT\"] = \"true\"\nos.environ[\"OMP_NUM_THREADS\"] = \"1\"\n\n# (Optional but recommended) remove crashy optional deps if present\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"-q\", \"uninstall\", \"-y\", \"tensorboard\", \"ray\", \"wandb\"], check=False)\n\n# Ensure ultralytics exists (do NOT install deps again)\nsubprocess.run([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"--no-deps\", \"ultralytics==8.2.0\"], check=True)\n\nWORK=\"/kaggle/working\"\nif WORK not in sys.path:\n    sys.path.insert(0, WORK)\nos.environ[\"PYTHONPATH\"] = WORK + \":\" + os.environ.get(\"PYTHONPATH\",\"\")\n\n# Make sitecustomize so DDP subprocess ranks also inherit safe loading\nPath(f\"{WORK}/sitecustomize.py\").write_text(r'''\nimport os\nos.environ.setdefault(\"WANDB_DISABLED\", \"true\")\nos.environ.setdefault(\"WANDB_MODE\", \"disabled\")\nos.environ.setdefault(\"WANDB_SILENT\", \"true\")\nos.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n\ntry:\n    import torch\n    try:\n        from ultralytics.nn.tasks import DetectionModel\n        torch.serialization.add_safe_globals([DetectionModel])\n    except Exception:\n        pass\n\n    if not getattr(torch, \"_weights_only_off\", False):\n        _orig = torch.load\n        def patched(*args, **kwargs):\n            kwargs.setdefault(\"weights_only\", False)\n            try:\n                return _orig(*args, **kwargs)\n            except TypeError:\n                kwargs.pop(\"weights_only\", None)\n                return _orig(*args, **kwargs)\n        torch.load = patched\n        torch._weights_only_off = True\nexcept Exception:\n    pass\n''')\n\nsys.modules.pop(\"sitecustomize\", None)\nimportlib.invalidate_caches()\nimport sitecustomize  # noqa\n\nimport torch, ultralytics\nprint(\"‚úÖ torch:\", torch.__version__, \"cuda:\", torch.cuda.is_available(), \"gpus:\", torch.cuda.device_count())\nprint(\"‚úÖ ultralytics:\", ultralytics.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T10:57:05.947095Z","iopub.execute_input":"2026-01-12T10:57:05.947418Z","iopub.status.idle":"2026-01-12T10:57:56.306239Z","shell.execute_reply.started":"2026-01-12T10:57:05.947391Z","shell.execute_reply":"2026-01-12T10:57:56.305441Z"}},"outputs":[{"name":"stdout","text":"     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 40.5/40.5 kB 1.5 MB/s eta 0:00:00\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 750.8/750.8 kB 13.4 MB/s eta 0:00:00\n‚úÖ torch: 2.8.0+cu126 cuda: True gpus: 2\n‚úÖ ultralytics: 8.2.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from pathlib import Path\n\n# Find best.pt from your input dataset\nbest_candidates = list(Path(\"/kaggle/input\").glob(\"**/baseline_640_2gpu/weights/best.pt\"))\nassert best_candidates, \"‚ùå best.pt not found. Ensure session-1-yolo-11v is added as Input.\"\nbest_pt = best_candidates[0]\nprint(\"‚úÖ best_pt:\", best_pt)\n\n# Find dataset root\ndata_candidates = list(Path(\"/kaggle/input\").glob(\"**/randomized_dataset\"))\nassert data_candidates, \"‚ùå randomized_dataset not found. Ensure crackathon-data is added as Input.\"\nDATA_ROOT = data_candidates[0]\nprint(\"‚úÖ DATA_ROOT:\", DATA_ROOT)\n\n# Write YAML\nyaml_path = Path(\"/kaggle/working/rdd.yaml\")\nyaml_path.write_text(f\"\"\"\npath: {DATA_ROOT}\ntrain: train/images\nval: val/images\ntest: test/images\nnames:\n  0: longitudinal_crack\n  1: transverse_crack\n  2: alligator_crack\n  3: other_corruption\n  4: pothole\n\"\"\".strip()+\"\\n\")\nprint(\"‚úÖ YAML:\", yaml_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T10:58:25.492818Z","iopub.execute_input":"2026-01-12T10:58:25.493725Z","iopub.status.idle":"2026-01-12T11:02:11.888885Z","shell.execute_reply.started":"2026-01-12T10:58:25.493693Z","shell.execute_reply":"2026-01-12T11:02:11.888241Z"}},"outputs":[{"name":"stdout","text":"‚úÖ best_pt: /kaggle/input/seven-hours/baseline_640_2gpu/weights/best.pt\n‚úÖ DATA_ROOT: /kaggle/input/crackathon-data/randomized_dataset\n‚úÖ YAML: /kaggle/working/rdd.yaml\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom ultralytics import YOLO\n\ndevice_val = 0 if torch.cuda.is_available() else \"cpu\"\nm = YOLO(str(best_pt))\nres = m.val(data=str(yaml_path), imgsz=640, device=device_val, verbose=False)\nprint(\"‚úÖ val mAP50:\", float(res.box.map50))\nprint(\"‚úÖ val mAP50-95:\", float(res.box.map))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"   # ‚úÖ allow both GPUs\nos.environ[\"NCCL_IB_DISABLE\"] = \"1\"\nos.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T10:56:57.264885Z","iopub.execute_input":"2026-01-12T10:56:57.265607Z","iopub.status.idle":"2026-01-12T10:56:57.269135Z","shell.execute_reply.started":"2026-01-12T10:56:57.265580Z","shell.execute_reply":"2026-01-12T10:56:57.268531Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!nvidia-smi\n!nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv,noheader\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, signal, subprocess\n\nme = os.getpid()\nq = subprocess.check_output(\n    \"nvidia-smi --query-compute-apps=pid,process_name --format=csv,noheader\",\n    shell=True\n).decode().strip().splitlines()\n\nkilled = []\nfor line in q:\n    pid_s, name = [x.strip() for x in line.split(\",\")]\n    pid = int(pid_s)\n    if pid != me and (\"python\" in name.lower()):\n        try:\n            os.kill(pid, signal.SIGKILL)\n            killed.append(pid)\n        except Exception as e:\n            print(\"Could not kill\", pid, e)\n\nprint(\"‚úÖ killed:\", killed)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T11:02:22.368795Z","iopub.execute_input":"2026-01-12T11:02:22.369228Z","iopub.status.idle":"2026-01-12T11:02:22.404517Z","shell.execute_reply.started":"2026-01-12T11:02:22.369201Z","shell.execute_reply":"2026-01-12T11:02:22.403837Z"}},"outputs":[{"name":"stdout","text":"‚úÖ killed: []\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import gc, torch\ngc.collect()\ntorch.cuda.empty_cache()\nprint(\"‚úÖ cleared\")\n!nvidia-smi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T11:02:29.694939Z","iopub.execute_input":"2026-01-12T11:02:29.695635Z","iopub.status.idle":"2026-01-12T11:02:30.013107Z","shell.execute_reply.started":"2026-01-12T11:02:29.695607Z","shell.execute_reply":"2026-01-12T11:02:30.012356Z"}},"outputs":[{"name":"stdout","text":"‚úÖ cleared\nMon Jan 12 11:02:29 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   43C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   44C    P8             11W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import time, torch\nfrom ultralytics import YOLO\n\nDEVICE = \"0,1\" if torch.cuda.is_available() and torch.cuda.device_count() >= 2 else 0\nBATCH = 32  # safest for 2xT4 at 640\n\nTARGET = 0.50\nTIME_LIMIT_SEC = int(4.0 * 3600)\nSTART = time.time()\n\ndef get_map5095(trainer):\n    m = getattr(trainer, \"metrics\", {})\n    if not isinstance(m, dict): return None\n    v = m.get(\"metrics/mAP50-95(B)\", None)\n    if v is None: v = m.get(\"metrics/mAP50-95\", None)\n    return float(v) if v is not None else None\n\ndef stop_cb(trainer):\n    if getattr(trainer, \"rank\", 0) in (-1, 0):\n        v = get_map5095(trainer)\n        if v is not None:\n            print(f\"\\n[EPOCH {trainer.epoch+1}] val mAP50-95={v:.4f}\")\n            if v >= TARGET:\n                print(\"‚úÖ Baseline reached, stopping Stage A.\")\n                trainer.stop = True\n                return\n    if time.time() - START > TIME_LIMIT_SEC:\n        print(\"‚è±Ô∏è Stage A time limit reached.\")\n        trainer.stop = True\n\nmodel = YOLO(str(best_pt))   # your carried weight\nmodel.callbacks.setdefault(\"on_fit_epoch_end\", [])\nmodel.callbacks[\"on_fit_epoch_end\"].append(stop_cb)\n\nmodel.train(\n    data=str(yaml_path),\n    imgsz=640,\n    epochs=400,\n    batch=BATCH,\n    device=DEVICE,\n    workers=2,\n    cache=False,\n    amp=True,\n    project=\"runs\",\n    name=\"stageA_640\",\n    patience=0,\n\n    optimizer=\"SGD\",\n    lr0=0.005,\n    lrf=0.01,\n    cos_lr=True,\n\n    mosaic=0.10,\n    mixup=0.0,\n    translate=0.10,\n    scale=0.30,\n    fliplr=0.5,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T11:02:37.972965Z","iopub.execute_input":"2026-01-12T11:02:37.973727Z"}},"outputs":[{"name":"stdout","text":"New https://pypi.org/project/ultralytics/8.3.252 available üòÉ Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.2.0 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n                                                           CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/input/seven-hours/baseline_640_2gpu/weights/best.pt, data=/kaggle/working/rdd.yaml, epochs=400, time=None, patience=0, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=0,1, workers=2, project=runs, name=stageA_640, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.3, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.1, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/stageA_640\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 17.2MB/s]","output_type":"stream"},{"name":"stdout","text":"\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5586655  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \nModel summary: 365 layers, 43633695 parameters, 43633679 gradients\n\nTransferred 595/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 58653 /root/.config/Ultralytics/DDP/_temp_xlxeid1u134500382144224.py\nUltralytics YOLOv8.2.0 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n                                                           CUDA:1 (Tesla T4, 15095MiB)\nTransferred 595/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 69.2MB/s]\n/usr/local/lib/python3.12/dist-packages/ultralytics/utils/checks.py:640: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(True):\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:261: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:261: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/crackathon-data/randomized_dataset/train/labels... 26385 images, 8073 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26385/26385 [02:09<00:00, 203.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/crackathon-data/randomized_dataset/train/images/000641.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/crackathon-data/randomized_dataset/train/images/005751.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /kaggle/input/crackathon-data/randomized_dataset/train/images/030717.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è Cache directory /kaggle/input/crackathon-data/randomized_dataset/train is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/data/augment.py:891: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n  A.ImageCompression(quality_lower=75, p=0.0),\n/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n  self._set_keys()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/crackathon-data/randomized_dataset/val/labels... 6000 images, 1792 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6000/6000 [00:27<00:00, 214.81it/s]16it/s]\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/crackathon-data/randomized_dataset/train/labels... 20295 images, 6210 backgrounds, 0 corrupt:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 20295/26385 [00:36<00:10, 568.84it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è Cache directory /kaggle/input/crackathon-data/randomized_dataset/val is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/crackathon-data/randomized_dataset/train/labels... 21104 images, 6440 backgrounds, 0 corrupt:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 21104/26385 [00:38<00:09, 545.95it/s]","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/stageA_640/labels.jpg... \n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/crackathon-data/randomized_dataset/train/labels... 23101 images, 7054 backgrounds, 0 corrupt:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 23101/26385 [00:42<00:06, 529.98it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.005, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/stageA_640\u001b[0m\nStarting training for 400 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/crackathon-data/randomized_dataset/train/labels... 26385 images, 8073 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26385/26385 [00:47<00:00, 551.83it/s]\n/usr/local/lib/python3.12/dist-packages/ultralytics/data/augment.py:891: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n  A.ImageCompression(quality_lower=75, p=0.0),\n/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.\n  self._set_keys()\n/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n      1/400      10.2G      1.435      1.323        1.5         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [13:21<00:00,  1.03it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:14<00:00,  1.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.635      0.564      0.609      0.329\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n      2/400      10.5G      1.445      1.314      1.506         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:46<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:08<00:00,  1.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.635      0.566      0.609      0.328\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n      3/400      10.6G      1.457      1.323      1.513         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:41<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:04<00:00,  1.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.612      0.551      0.584       0.31\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n      4/400      10.8G      1.474      1.355       1.52         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:41<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:04<00:00,  1.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.609      0.563      0.588       0.31\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      5/400        11G      1.473       1.34      1.525         12        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:41<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:05<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.613      0.569      0.587      0.311\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n  0%|          | 0/825 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      6/400      11.2G      1.457      1.315       1.51         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:41<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:05<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.614      0.561       0.59      0.312\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n  0%|          | 0/825 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      7/400      11.3G      1.452      1.309       1.51         10        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:40<00:00,  1.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:05<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443       0.63       0.55       0.59      0.315\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n      8/400      11.5G      1.449      1.278      1.498         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:40<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:06<00:00,  1.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.616      0.572      0.593      0.314\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n      9/400      11.7G      1.436      1.265       1.49         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:40<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:05<00:00,  1.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.624      0.551      0.588      0.308\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n     10/400      11.9G      1.421      1.251      1.482          9        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:41<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:04<00:00,  1.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.618      0.565      0.589      0.312\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n     11/400      12.1G      1.418      1.234      1.477         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:41<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:04<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.635      0.556      0.591      0.313\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n     12/400      12.3G      1.413      1.219      1.474         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:42<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:05<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.625      0.573      0.597      0.315\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n     13/400      12.4G      1.409      1.204      1.471         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:41<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:04<00:00,  1.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.634      0.571      0.604       0.32\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n     14/400      12.7G       1.41        1.2      1.464         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:41<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:04<00:00,  1.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.637      0.567      0.609      0.324\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n     15/400      12.8G      1.396      1.179       1.46         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:40<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:04<00:00,  1.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.645      0.571      0.607      0.324\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n     16/400        13G      1.378      1.168      1.449         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:41<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:06<00:00,  1.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.633      0.585      0.611      0.326\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n     17/400      13.2G      1.374      1.148      1.442         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 825/825 [12:41<00:00,  1.08it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 188/188 [02:06<00:00,  1.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       6000      10443      0.646      0.581      0.611      0.328\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/825 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/ultralytics/engine/trainer.py:368: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(self.amp):\n     18/400      13.4G      1.354      1.113      1.428         21        640:  18%|‚ñà‚ñä        | 150/825 [02:13<10:08,  1.11it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}